{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Transcription Testing with Whisper API\n",
                "\n",
                "This notebook tests audio transcription capabilities using OpenAI's Whisper API.\n",
                "\n",
                "## Objectives\n",
                "1. Test Whisper API integration\n",
                "2. Benchmark transcription accuracy\n",
                "3. Test different audio formats and quality levels\n",
                "4. Measure processing time\n",
                "\n",
                "## Setup\n",
                "- Requires OpenAI API key in `.env`\n",
                "- Test audio files in `test_audio/` directory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "from pathlib import Path\n",
                "from dotenv import load_dotenv\n",
                "from openai import OpenAI\n",
                "import time\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv()\n",
                "\n",
                "# Initialize OpenAI client\n",
                "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
                "\n",
                "print(\"âœ… OpenAI client initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 1: Basic Transcription"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def transcribe_audio(audio_file_path: str, language: str = None):\n",
                "    \"\"\"\n",
                "    Transcribe audio file using Whisper API\n",
                "    \n",
                "    Args:\n",
                "        audio_file_path: Path to audio file\n",
                "        language: Optional ISO-639-1 language code (e.g., 'en', 'es')\n",
                "    \n",
                "    Returns:\n",
                "        dict: Transcription result with text and metadata\n",
                "    \"\"\"\n",
                "    start_time = time.time()\n",
                "    \n",
                "    with open(audio_file_path, 'rb') as audio_file:\n",
                "        if language:\n",
                "            transcript = client.audio.transcriptions.create(\n",
                "                model=\"whisper-1\",\n",
                "                file=audio_file,\n",
                "                language=language,\n",
                "                response_format=\"verbose_json\"\n",
                "            )\n",
                "        else:\n",
                "            transcript = client.audio.transcriptions.create(\n",
                "                model=\"whisper-1\",\n",
                "                file=audio_file,\n",
                "                response_format=\"verbose_json\"\n",
                "            )\n",
                "    \n",
                "    processing_time = time.time() - start_time\n",
                "    \n",
                "    return {\n",
                "        'text': transcript.text,\n",
                "        'language': transcript.language if hasattr(transcript, 'language') else 'unknown',\n",
                "        'duration': transcript.duration if hasattr(transcript, 'duration') else 0,\n",
                "        'processing_time': processing_time\n",
                "    }\n",
                "\n",
                "# Test with sample audio file (you'll need to provide your own)\n",
                "# audio_path = \"test_audio/sample_medical_interpretation.mp3\"\n",
                "# result = transcribe_audio(audio_path, language='en')\n",
                "# print(f\"Transcription: {result['text']}\")\n",
                "# print(f\"Language: {result['language']}\")\n",
                "# print(f\"Duration: {result['duration']:.2f}s\")\n",
                "# print(f\"Processing Time: {result['processing_time']:.2f}s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 2: Bilingual Medical Interpretation\n",
                "\n",
                "Test transcription of a medical interpretation session with code-switching between English and Spanish."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Transcribe bilingual interpretation\n",
                "# bilingual_audio = \"test_audio/bilingual_interpretation.mp3\"\n",
                "# result = transcribe_audio(bilingual_audio)\n",
                "# print(f\"Detected Language: {result['language']}\")\n",
                "# print(f\"Full Transcript:\\n{result['text']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 3: Accuracy Benchmarking\n",
                "\n",
                "Compare Whisper transcription against ground truth transcripts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_wer(reference: str, hypothesis: str) -> float:\n",
                "    \"\"\"\n",
                "    Calculate Word Error Rate (WER)\n",
                "    \n",
                "    WER = (S + D + I) / N\n",
                "    S = substitutions, D = deletions, I = insertions, N = total words in reference\n",
                "    \"\"\"\n",
                "    ref_words = reference.lower().split()\n",
                "    hyp_words = hypothesis.lower().split()\n",
                "    \n",
                "    # Simple Levenshtein distance calculation\n",
                "    d = [[0] * (len(hyp_words) + 1) for _ in range(len(ref_words) + 1)]\n",
                "    \n",
                "    for i in range(len(ref_words) + 1):\n",
                "        d[i][0] = i\n",
                "    for j in range(len(hyp_words) + 1):\n",
                "        d[0][j] = j\n",
                "    \n",
                "    for i in range(1, len(ref_words) + 1):\n",
                "        for j in range(1, len(hyp_words) + 1):\n",
                "            if ref_words[i-1] == hyp_words[j-1]:\n",
                "                d[i][j] = d[i-1][j-1]\n",
                "            else:\n",
                "                substitution = d[i-1][j-1] + 1\n",
                "                insertion = d[i][j-1] + 1\n",
                "                deletion = d[i-1][j] + 1\n",
                "                d[i][j] = min(substitution, insertion, deletion)\n",
                "    \n",
                "    wer = d[len(ref_words)][len(hyp_words)] / len(ref_words) if ref_words else 0\n",
                "    return wer\n",
                "\n",
                "# Example usage:\n",
                "# ground_truth = \"The patient has hypertension and diabetes.\"\n",
                "# whisper_output = \"The patient has high blood pressure and diabetes.\"\n",
                "# wer = calculate_wer(ground_truth, whisper_output)\n",
                "# print(f\"Word Error Rate: {wer:.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "1. Create a collection of test audio files (various accents, audio quality, medical terminology)\n",
                "2. Benchmark WER across different scenarios\n",
                "3. Test edge cases (background noise, multiple speakers, heavy accents)\n",
                "4. Implement speaker diarization if needed\n",
                "5. Move successful patterns to `app/nlp/transcription.py`"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}