{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# scispaCy Medical Entity Recognition\n",
                "\n",
                "This notebook tests scispaCy's capabilities for recognizing medical entities in interpreter transcripts.\n",
                "\n",
                "## Objectives\n",
                "1. Test medical entity recognition (diseases, medications, procedures)\n",
                "2. Benchmark accuracy on medical terminology\n",
                "3. Test negation detection with negspaCy\n",
                "4. Identify medical concept omissions\n",
                "5. Link entities to UMLS concepts\n",
                "\n",
                "## Setup\n",
                "Requires scispaCy models:\n",
                "- `en_core_sci_lg` - Large biomedical model\n",
                "- `en_ner_bc5cdr_md` - Disease & Chemical recognition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import spacy\n",
                "import scispacy\n",
                "from scispacy.linking import EntityLinker\n",
                "from spacy import displacy\n",
                "import pandas as pd\n",
                "from negspacy.negation import Negex\n",
                "\n",
                "# Install scispaCy models:\n",
                "# !pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_lg-0.5.0.tar.gz\n",
                "# !pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz\n",
                "\n",
                "# Load scispaCy model\n",
                "nlp = spacy.load(\"en_core_sci_lg\")\n",
                "\n",
                "# Add entity linker (links to UMLS)\n",
                "nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"linker_name\": \"umls\"})\n",
                "\n",
                "# Add negation detection\n",
                "nlp.add_pipe(\"negex\")\n",
                "\n",
                "print(\"✅ scispaCy models loaded\")\n",
                "print(f\"Pipeline: {nlp.pipe_names}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 1: Medical Entity Recognition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_medical_entities(text: str):\n",
                "    \"\"\"\n",
                "    Extract medical entities from text\n",
                "    \"\"\"\n",
                "    doc = nlp(text)\n",
                "    \n",
                "    entities = []\n",
                "    for ent in doc.ents:\n",
                "        entities.append({\n",
                "            'text': ent.text,\n",
                "            'label': ent.label_,\n",
                "            'start': ent.start_char,\n",
                "            'end': ent.end_char\n",
                "        })\n",
                "    \n",
                "    return pd.DataFrame(entities)\n",
                "\n",
                "# Example\n",
                "medical_text = \"\"\"\n",
                "The patient presented with acute myocardial infarction. \n",
                "We initiated treatment with aspirin, clopidogrel, and atorvastatin. \n",
                "The patient has a history of type 2 diabetes mellitus and hypertension.\n",
                "\"\"\"\n",
                "\n",
                "entities_df = extract_medical_entities(medical_text)\n",
                "print(entities_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 2: Entity Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_medical_entities(text: str):\n",
                "    \"\"\"\n",
                "    Visualize medical entities in text\n",
                "    \"\"\"\n",
                "    doc = nlp(text)\n",
                "    displacy.render(doc, style=\"ent\", jupyter=True)\n",
                "\n",
                "# Example\n",
                "# visualize_medical_entities(medical_text)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 3: UMLS Concept Linking"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def link_to_umls(text: str, top_k: int = 3):\n",
                "    \"\"\"\n",
                "    Link medical entities to UMLS concepts\n",
                "    \"\"\"\n",
                "    doc = nlp(text)\n",
                "    linker = nlp.get_pipe(\"scispacy_linker\")\n",
                "    \n",
                "    linked_entities = []\n",
                "    for ent in doc.ents:\n",
                "        if ent._.kb_ents:\n",
                "            # Get top K linked concepts\n",
                "            for umls_ent in ent._.kb_ents[:top_k]:\n",
                "                cui = umls_ent[0]\n",
                "                score = umls_ent[1]\n",
                "                \n",
                "                # Get concept details\n",
                "                concept = linker.kb.cui_to_entity[cui]\n",
                "                \n",
                "                linked_entities.append({\n",
                "                    'entity_text': ent.text,\n",
                "                    'entity_label': ent.label_,\n",
                "                    'umls_cui': cui,\n",
                "                    'canonical_name': concept.canonical_name,\n",
                "                    'score': score,\n",
                "                    'definition': concept.definition if hasattr(concept, 'definition') else 'N/A'\n",
                "                })\n",
                "    \n",
                "    return pd.DataFrame(linked_entities)\n",
                "\n",
                "# Example\n",
                "# umls_links = link_to_umls(medical_text)\n",
                "# print(umls_links)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 4: Negation Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def detect_negations(text: str):\n",
                "    \"\"\"\n",
                "    Detect negated medical entities\n",
                "    \"\"\"\n",
                "    doc = nlp(text)\n",
                "    \n",
                "    negations = []\n",
                "    for ent in doc.ents:\n",
                "        negations.append({\n",
                "            'text': ent.text,\n",
                "            'label': ent.label_,\n",
                "            'is_negated': ent._.negex,\n",
                "            'context': doc[max(0, ent.start-5):min(len(doc), ent.end+5)].text\n",
                "        })\n",
                "    \n",
                "    return pd.DataFrame(negations)\n",
                "\n",
                "# Example with negations\n",
                "negation_text = \"\"\"\n",
                "The patient denies chest pain or shortness of breath.\n",
                "No history of diabetes.\n",
                "The patient has hypertension but no signs of heart failure.\n",
                "\"\"\"\n",
                "\n",
                "negations_df = detect_negations(negation_text)\n",
                "print(negations_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 5: Medical Terminology Accuracy Assessment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_medical_accuracy(source: str, interpretation: str):\n",
                "    \"\"\"\n",
                "    Compare medical terminology accuracy between source and interpretation\n",
                "    \"\"\"\n",
                "    doc_source = nlp(source)\n",
                "    doc_interp = nlp(interpretation)\n",
                "    \n",
                "    # Extract medical entities\n",
                "    source_entities = {ent.text.lower(): ent.label_ for ent in doc_source.ents}\n",
                "    interp_entities = {ent.text.lower(): ent.label_ for ent in doc_interp.ents}\n",
                "    \n",
                "    # Find omitted medical terms\n",
                "    omissions = set(source_entities.keys()) - set(interp_entities.keys())\n",
                "    \n",
                "    # Find incorrectly added terms\n",
                "    additions = set(interp_entities.keys()) - set(source_entities.keys())\n",
                "    \n",
                "    # Calculate accuracy\n",
                "    correct = len(set(source_entities.keys()) & set(interp_entities.keys()))\n",
                "    total_source = len(source_entities)\n",
                "    \n",
                "    accuracy = correct / total_source if total_source > 0 else 0\n",
                "    \n",
                "    print(f\"Medical Terminology Accuracy: {accuracy:.2%}\")\n",
                "    print(f\"\\nSource Entities ({len(source_entities)}): {list(source_entities.keys())}\")\n",
                "    print(f\"Interpretation Entities ({len(interp_entities)}): {list(interp_entities.keys())}\")\n",
                "    print(f\"\\nOmitted Terms: {list(omissions)}\")\n",
                "    print(f\"Added Terms: {list(additions)}\")\n",
                "    \n",
                "    return {\n",
                "        'accuracy': accuracy,\n",
                "        'omissions': list(omissions),\n",
                "        'additions': list(additions),\n",
                "        'correct_count': correct,\n",
                "        'total_count': total_source\n",
                "    }\n",
                "\n",
                "# Example\n",
                "source = \"\"\"\n",
                "The patient presented with acute myocardial infarction. \n",
                "We prescribed aspirin and atorvastatin.\n",
                "\"\"\"\n",
                "\n",
                "interpretation = \"\"\"\n",
                "The patient had a heart attack. \n",
                "We gave them aspirin and cholesterol medication.\n",
                "\"\"\"\n",
                "\n",
                "# result = compare_medical_accuracy(source, interpretation)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 6: Medication Name Extraction (Generic vs Brand)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_medications(text: str):\n",
                "    \"\"\"\n",
                "    Extract medication entities and link to UMLS for generic/brand name mapping\n",
                "    \"\"\"\n",
                "    doc = nlp(text)\n",
                "    linker = nlp.get_pipe(\"scispacy_linker\")\n",
                "    \n",
                "    medications = []\n",
                "    for ent in doc.ents:\n",
                "        if ent.label_ in ['CHEMICAL', 'DRUG']:\n",
                "            med_info = {\n",
                "                'text': ent.text,\n",
                "                'label': ent.label_,\n",
                "                'is_negated': ent._.negex\n",
                "            }\n",
                "            \n",
                "            # Get UMLS canonical name (often generic name)\n",
                "            if ent._.kb_ents:\n",
                "                cui = ent._.kb_ents[0][0]\n",
                "                concept = linker.kb.cui_to_entity[cui]\n",
                "                med_info['canonical_name'] = concept.canonical_name\n",
                "                med_info['umls_cui'] = cui\n",
                "            \n",
                "            medications.append(med_info)\n",
                "    \n",
                "    return pd.DataFrame(medications)\n",
                "\n",
                "# Example\n",
                "med_text = \"\"\"\n",
                "The patient is taking Lipitor 20mg daily. \n",
                "We also prescribed metformin and Plavix.\n",
                "The patient is not taking aspirin.\n",
                "\"\"\"\n",
                "\n",
                "# meds_df = extract_medications(med_text)\n",
                "# print(meds_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "1. Create medical interpretation test dataset\n",
                "2. Benchmark entity recognition accuracy\n",
                "3. Build medication name mapping (generic ↔ brand)\n",
                "4. Test multilingual medical entity recognition (Spanish)\n",
                "5. Integrate with Claude for feedback generation (next notebook)\n",
                "6. Move successful patterns to `app/nlp/medical_ner.py`"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}